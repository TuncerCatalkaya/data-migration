@startuml
start

:Start the process;
:Initialize start time;
:get object from S3;
:get projectId and fileName from S3 key;
:get ScopeModel using ProjectsUsecase;

if (ScopeEntity finished?) then (yes)
    :Log "Scope already processed";
    stop
else (no)
    :Check for existing checkpoint;
    if (Checkpoint exists?) then (yes)
        :Use existing batchSize;
    else (no)
        :Create and save new checkpoint;
        :Set batchSize from configuration;
    endif
endif

:Read object from S3;
:Read CSV headers;

while (more lines?) is (yes)
    :Process each line;
    :Calculate batchIndex;
    if (Batch already processed?) then (yes)
        :Log "Batch already processed";
'        continue
    else (no)
        :Add item to batch;
        if (batch size reached?) then (yes)
            :Store batch;
            fork
                :Process batch asynchronously;
            fork again
                :Clear batch;
            end fork
        endif
    endif
endwhile (no)

if (Remaining items in batch?) then (yes)
    :Store remaining batch;
    fork
        :Process remaining items asynchronously;
    fork again
        :Clear remaining batch;
    end fork
endif

:Wait for all asynchronous batches to complete;

if (Processing failed?) then (yes)
    :Log "Processing failed";
else (no)
    :Mark scope as finished;
    :Log "Processing completed";
endif

stop
@enduml
